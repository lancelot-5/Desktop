{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def MLSMOTE(X,y, n_sample):\n",
    "    \"\"\"Give the augmented data using MLSMOTE algorithm\n",
    "    args\n",
    "    X: pandas.DataFrame, input vector DataFrame\n",
    "    y: pandas.DataFrame, feature vector dataframe\n",
    "    n_sample: int, number of newly generated sample\n",
    "    return\n",
    "    new_X: pandas.DataFrame, augmented feature vector data\n",
    "    target: pandas.DataFrame, augmented target vector data\"\"\"\n",
    "    indices2 = nearest_neighbour(X)\n",
    "    n = len(indices2)\n",
    "    new_X = np.zeros((n_sample, X.shape[1]))\n",
    "    target = np.zeros((n_sample, y.shape[1]))\n",
    "    for i in range(n_sample):\n",
    "        reference = random.randint(0,n-1)\n",
    "        neighbour = random.choice(indices2[reference,1:])\n",
    "        all_point = indices2[reference]\n",
    "        nn_df = y[y.index.isin(all_point)]\n",
    "        ser = nn_df.sum(axis = 0, skipna = True)\n",
    "        target[i] = np.array([1 if val>2 else 0 for val in ser])\n",
    "        ratio = random.random()\n",
    "        gap = X.loc[reference,:] - X.loc[neighbour,:]\n",
    "        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n",
    "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
    "    target = pd.DataFrame(target, columns=y.columns)\n",
    "    new_X = pd.concat([X, new_X], axis=0)\n",
    "    target = pd.concat([y, target], axis=0)\n",
    "    return new_X, target\n",
    "def get_minority_instace(X, y):\n",
    "    index = get_index(y)\n",
    "    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n",
    "    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n",
    "    return X_sub, y_sub\n",
    "def nearest_neighbour(X):\n",
    "    \"\"\"\n",
    "    Give index of 5 nearest neighbor of all the instance\n",
    "    args\n",
    "    X: np.array, array whose nearest neighbor has to find\n",
    "    return\n",
    "    indices: list of list, index of 5 NN of each element in X\n",
    "    \"\"\"\n",
    "    nbs=NearestNeighbors(n_neighbors=5,metric='euclidean',algorithm='kd_tree').fit(X)\n",
    "    euclidean,indices= nbs.kneighbors(X)\n",
    "    return indices\n",
    "def get_index(df):\n",
    "    \"\"\"\n",
    "    give the index of all tail_label rows\n",
    "    args\n",
    "    df: pandas.DataFrame, target label df from which index for tail label has to identified\n",
    "    return\n",
    "    index: list, a list containing index number of all the tail label\n",
    "    \"\"\"\n",
    "    tail_labels = get_tail_label(df)\n",
    "    index = set()\n",
    "    for tail_label in tail_labels:\n",
    "        sub_index = set(df[df[tail_label]==1].index)\n",
    "        index = index.union(sub_index)\n",
    "    return list(index)\n",
    "def get_tail_label(df):\n",
    "    columns = df.columns\n",
    "    n = len(columns)\n",
    "    irpl = np.zeros(n)\n",
    "    for column in range(n):\n",
    "        irpl[column] = df[columns[column]].value_counts()[1]\n",
    "    irpl = max(irpl)/irpl\n",
    "    mir = np.average(irpl)\n",
    "    tail_label = []\n",
    "    for i in range(n):\n",
    "        if irpl[i] > mir:\n",
    "            tail_label.append(columns[i])\n",
    "    return tail_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'arff' has no attribute 'DENSE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23456\\457143066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlabel_count_datasheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'emotions'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yeast'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bibtex'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m159\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 1.获取数据集(训练集，测试集)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_from_arff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"emotions/emotions-train.arff\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_count_datasheet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'emotions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_from_arff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"emotions/emotions-test.arff\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_count_datasheet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'emotions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# 2.调用MLSMOTE过采样算法进行过采样(https://github.com/niteshsukhwani/MLSMOTE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\pythoncv\\lib\\site-packages\\skmultilearn\\dataset.py\u001b[0m in \u001b[0;36mload_from_arff\u001b[1;34m(filename, label_count, label_location, input_feature_type, encode_nominal, load_sparse, return_attribute_definitions)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mload_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         arff_frame = arff.load(\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_nominal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_nominal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDENSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         )\n\u001b[0;32m    218\u001b[0m         matrix = sparse.csr_matrix(\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'arff' has no attribute 'DENSE'"
     ]
    }
   ],
   "source": [
    "from skmultilearn.dataset import load_from_arff\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from skmultilearn.problem_transform import BinaryRelevance, LabelPowerset\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "#import mlsmote\n",
    "label_count_datasheet = {'emotions': 6, 'yeast': 14, 'bibtex': 159}\n",
    "# 1.获取数据集(训练集，测试集)\n",
    "X_train, y_train = load_from_arff(r\"emotions/emotions-train.arff\", label_count_datasheet['emotions'])\n",
    "X_test, y_test = load_from_arff(r\"emotions/emotions-test.arff\", label_count_datasheet['emotions'])\n",
    "# 2.调用MLSMOTE过采样算法进行过采样(https://github.com/niteshsukhwani/MLSMOTE)\n",
    "X_train = pd.DataFrame(X_train.toarray())\n",
    "y_train = pd.DataFrame(y_train.toarray())\n",
    "X_sub, y_sub = get_minority_instace(X_train, y_train)\n",
    "# 得到过采样后的数据\n",
    "X_resampled_mlsmote, y_resampled_mlsmote = MLSMOTE(X_sub, y_sub, 100)\n",
    "X_resampled_mlsmote = X_resampled_mlsmote.append(X_train)\n",
    "y_resampled_mlsmote = y_resampled_mlsmote.append(y_train)\n",
    "# 3.训练BR分类器（基分类器使用SVM）\n",
    "clf = BinaryRelevance(classifier=SVC())\n",
    "clf_oversampled = BinaryRelevance(classifier=SVC())\n",
    "# clf = LabelPowerset(classifier=SVC())\n",
    "# clf_oversampled = LabelPowerset(classifier=SVC())\n",
    "# 4.获取预测结果\n",
    "pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "pred_oversampled = clf_oversampled.fit(X_resampled_mlsmote, y_resampled_mlsmote).predict(X_test)\n",
    "# 5.使用Macro ACU和Macro F1-score评估预测结果\n",
    "print(\"Macro AUC/F1 for original data: \", roc_auc_score(y_test.toarray(), pred.toarray(), average=\"macro\"),\n",
    "f1_score(y_test, pred, average=\"macro\"))\n",
    "print(\"Macro AUC/F1 for oversampled data: \", roc_auc_score(y_test.toarray(), pred_oversampled.toarray(), average=\"macro\"),\n",
    "f1_score(y_test, pred_oversampled, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pythoncv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "489abf6f87bff1d62ff0d75e7fc9ae8fd3b1765d1b578585ccda4fa8b2e827c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
